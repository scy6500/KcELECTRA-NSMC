{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7403681c",
   "metadata": {},
   "source": [
    "# NSMC-Sentimental-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1491792e",
   "metadata": {},
   "source": [
    "본 과정은 Ainize Workspace에서 beomi/KcELECTRA-base 모델을 NSMC(Naver sentiment movie corpus) 데이터 셋으로 학습하는 과정입니다.\n",
    "\n",
    "최종 목표는 학습된 모델을 통해 Sentimental Analysis를 하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf119ca7",
   "metadata": {},
   "source": [
    "### Parameters 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fcce6",
   "metadata": {},
   "source": [
    "학습에 사용될 parameters(학습/평가 데이터 경로, 에폭 등)를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37e50d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'train_data_path': './nsmc/ratings_train.txt',\n",
    "    'val_data_path': './nsmc/ratings_test.txt',\n",
    "    'save_path': './model',\n",
    "    'max_epochs': 1,\n",
    "    'model_path': 'beomi/KcELECTRA-base',\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 5e-5,\n",
    "    'warmup_ratio': 0.0,\n",
    "    'max_seq_len': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f4fde",
   "metadata": {},
   "source": [
    "### 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808c1a9",
   "metadata": {},
   "source": [
    "우선 데이터를 살펴보겠습니다. \n",
    "\n",
    "데이터에는 영화 리뷰와 리뷰에 대한 라벨이 포함되어 있습니다. 평점이 10, 9인 리뷰에 대해서는 긍정(1), 평점이 1, 2, 3, 4인 리뷰에 대해서는 부정(0)으로 라벨링되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccea3394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(args[\"train_data_path\"], sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aada41",
   "metadata": {},
   "source": [
    "다운로드 받은 nsmc 데이터로부터 학습 데이터를 만들기 위해 Pytorch Dataset을 만들어 줍니다. \n",
    "\n",
    "데이터에 NaN 값과 중복 된 값이 포함되어 있어 이를 제거하는 작업과 입력으로 들어온 문자열을 max_length까지 자르는 작업을 진행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a337033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length):\n",
    "        df = pd.read_csv(csv_file, sep='\\t')\n",
    "        # NaN 값 제거\n",
    "        df = df.dropna(axis=0)\n",
    "        # 중복 제거\n",
    "        df.drop_duplicates(subset=['document'], inplace=True)\n",
    "        self.input_ids = tokenizer.batch_encode_plus(\n",
    "            df['document'].to_list(),\n",
    "            padding='max_length',\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=False,\n",
    "            truncation=True,\n",
    "        )['input_ids']\n",
    "        self.labels = torch.LongTensor(df['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d0ef9",
   "metadata": {},
   "source": [
    "### Model 및 Tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956319f9",
   "metadata": {},
   "source": [
    "학습에 사용할 모델과 Tokenizer 파일을 Huggingface에서 불러옵니다.\n",
    "\n",
    "모델을 불러오면 경고가 발생하는 데 이는 ElectraForSequenceClassification를 fine-tuning 하기 전에는 모델의 성능이 좋지 않을 것이라고 알려줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4c2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraForSequenceClassification, ElectraTokenizerFast\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(args['model_path'])\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(args['model_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c188f",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc33765",
   "metadata": {},
   "source": [
    "모델을 학습합니다. 학습에 사용할 파라메터는 args에서 정의 하였습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32306374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(model, train_dataloader, args):\n",
    "    model.train()\n",
    "    model.to('cuda')\n",
    "    global_total_step = len(train_dataloader) * args['max_epochs']\n",
    "    global_step = 0\n",
    "    optimizer = AdamW(model.parameters(), lr=args['learning_rate'], weight_decay=0.0)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=global_total_step)\n",
    "    with tqdm(total=global_total_step, unit='step') as t:\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for epoch in range(args['max_epochs']):\n",
    "            for batch in train_dataloader:\n",
    "                global_step += 1\n",
    "                b_input_ids = batch[0].to('cuda', non_blocking=True)\n",
    "                b_labels = batch[1].to('cuda', non_blocking=True)\n",
    "                model.zero_grad(set_to_none=True)\n",
    "                outputs = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    labels=b_labels\n",
    "                )\n",
    "                loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                preds = logits.detach().argmax(dim=-1).cpu().numpy()\n",
    "                out_label_ids = b_labels.detach().cpu().numpy()\n",
    "                total_correct += (preds == out_label_ids).sum()\n",
    "\n",
    "                batch_loss = loss.item() * len(b_input_ids)\n",
    "\n",
    "                total += len(b_input_ids)\n",
    "                total_loss += batch_loss\n",
    "\n",
    "                t.set_postfix(loss='{:.6f}'.format(batch_loss),\n",
    "                              accuracy='{:.2f}'.format(total_correct / total * 100))\n",
    "                t.update(1)\n",
    "                del b_input_ids\n",
    "                del outputs\n",
    "                del loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8bf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data_set = NSMCDataset(args['train_data_path'], tokenizer, args['max_seq_len'])\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_data_set,\n",
    "    batch_size=args['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b4e427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e032a2257c614bbda20ccff8c7d5a2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4569 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, train_data_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16d735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(args['save_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66602fb",
   "metadata": {},
   "source": [
    "### Smaple Data 넣어 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54130ce9",
   "metadata": {},
   "source": [
    "학습된 모델에 Smaple Data를 넣어 결과를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85edf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평점 10\n",
    "pos_text = '이방원을 다룬 드라마중 최고였다고 자부함. 진짜 이방원을 보여준 듯이 연기와 인물묘사나 주변상황이 재밌었고 스토리도 진부하지 않았음. 다시 이런드라마를 볼수 있을지~ 진짜 이런 드라마하나 또 나왔음 함.'\n",
    "# 평점 0\n",
    "neg_text = '핵노잼 후기보고 낙였네 방금보고왔는데 개실망 재미없어요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dedb03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이방원을 다룬 드라마중 최고였다고 자부함. 진짜 이방원을 보여준 듯이 연기와 인물묘사나 주변상황이 재밌었고 스토리도 진부하지 않았음. 다시 이런드라마를 볼수 있을지~ 진짜 이런 드라마하나 또 나왔음 함. : 1\n",
      "핵노잼 후기보고 낙였네 방금보고왔는데 개실망 재미없어요 : 0\n"
     ]
    }
   ],
   "source": [
    "pos_input_vector = tokenizer.encode(pos_text, return_tensors='pt').to('cuda')\n",
    "pos_pred = model(input_ids=pos_input_vector, labels=None).logits.argmax(dim=-1).tolist()\n",
    "print(f'{pos_text} : {pos_pred[0]}')\n",
    "\n",
    "neg_input_vector = tokenizer.encode(neg_text, return_tensors='pt').to('cuda')\n",
    "neg_pred = model(input_ids=neg_input_vector, labels=None).logits.argmax(dim=-1).tolist()\n",
    "print(f'{neg_text} : {neg_pred[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbba4f",
   "metadata": {},
   "source": [
    "지금까지 beomi/KcELECTRA-base 모델을 NSMC(Naver sentiment movie corpus)데이터 셋으로 학습하는 과정을 진행해보았습니다.\n",
    "\n",
    "beomi/kcbert-base, beomi/kcbert-large 등 다른 모델들도 NSMC로 학습하여 어떤 결과가 나오는 지 확인해보세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
